
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>La arquitectura transformer &#8212; Minería de Textos</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/estilos.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Práctica. Lectura y documentación del código de un extractor de entidades" href="bloque2_practica.html" />
    <link rel="prev" title="Representaciones de palabras y oraciones" href="bloque2_embeddings.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo-master-ca.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Minería de Textos</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Materiales de Minería de Textos
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="bloque1.html">
   Introducción a la minería de textos
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_1Introduccion.html">
     Minería de textos y procesamiento del lenguaje natural.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_2CategorialSintactico.html">
     Análisis categorial y sintáctico
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_3AnalisisSemantico.html">
     Análisis semántico
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_Practica1.html">
     Práctica 1.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_4AnalisisSemanticoVectorial.html">
     Análisis semántico vectorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_Practica2.html">
     Práctica 1b :
     <em>
      Topic modeling
     </em>
     .
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="bloque2.html">
   Técnicas para la minería de textos
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="bloque2_historia.html">
     Revisión histórica
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque2_embeddings.html">
     Representaciones de palabras y oraciones
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     La arquitectura transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque2_practica.html">
     Práctica. Lectura y documentación del código de un extractor de entidades
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="bloque3.html">
   Aplicaciones de la minería de textos
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_t1_aplicaciones.html">
     T1. Aplicaciones generales
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_t2_subaplicaciones-benchmarks.html">
     T2. Aplicaciones específicas y Benchmacks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_t2.1_analisis_sentimientos.html">
     T2.1. Aplicaciones específicas. Análisis de Sentimientos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_t3.1_metricas.html">
     T3. Métricas de Evaluación
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_t4_huggingface.html">
     T4. Centralización de datasets y modelos: Huggingface
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_p1_SA-Pipeline-Reviews.html">
     P1.1. Pipeline simple
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_p2_SA-Transformers-Basic.html">
     P1.2. APIs Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_p3_SA-Transformers-Training-FineTuning.html">
     P2. Reajustar modelos Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_p4_SA-Transformers-Training-Custom.html">
     P3. Composición de vectores de características
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_ev.html">
     Ev. Evaluación de prácticas
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="content.html">
   Content in Jupyter Book
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="markdown.html">
     Markdown Files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="notebooks.html">
     Content with notebooks
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/bloque2_transformer.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#el-transformer">
   El transformer
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ecuaciones-del-transformer">
     Ecuaciones del transformer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#un-simil-del-mecanismo-de-autoatencion">
     Un símil del mecanismo de autoatención
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#normalizacion-de-capa">
     Normalización de capa
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizacion-de-embeddings-contextuales">
   Visualización de embeddings contextuales
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#para-saber-mas">
   Para saber más
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#referencias">
   Referencias
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>La arquitectura transformer</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#el-transformer">
   El transformer
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ecuaciones-del-transformer">
     Ecuaciones del transformer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#un-simil-del-mecanismo-de-autoatencion">
     Un símil del mecanismo de autoatención
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#normalizacion-de-capa">
     Normalización de capa
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizacion-de-embeddings-contextuales">
   Visualización de embeddings contextuales
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#para-saber-mas">
   Para saber más
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#referencias">
   Referencias
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="section" id="la-arquitectura-transformer">
<h1>La arquitectura transformer<a class="headerlink" href="#la-arquitectura-transformer" title="Permalink to this headline">¶</a></h1>
<p>En 2017 las redes neuronales recurrentes basadas en unidades LSTM como las que hemos estudiado eran la arquitectura habitual para el procesamiento neuronal de secuencias, en general, y del lenguaje natural, en particular. Algunos investigadores comenzaban a obtener también buenos resultados en esta área con las redes neuronales convolucionales, tradicionalmente empleadas con imágenes. Por otro lado, los mecanismos de atención introducidos unos años antes en las redes recurrentes habían mejorado su capacidad para resolver ciertas tareas y abierto el abánico de posibilidades de estos modelos. Además, el modelo conocido como codificador-descodificador (<em>encoder-decoder</em> en inglés) se convertía en la piedra angular de los sistemas que transformaban una secuencia en otra (sistemas conocidos como <em>seq2seq</em> como, por ejemplo, los sistemas de traducción automática o de obtención de resúmenes). A mediados de 2017, sin embargo, aparece un artículo <a class="bibtex reference internal" href="#allyouneed" id="id1">[VSP+17]</a> que propone eliminar la recurrencia del modelo codificador-descodificador y sustituirla por lo que se denomina autoatención (<em>self-attention</em>); aunque el artículo se centra en la tarea de la traducción automática, en muy poco tiempo la aplicación de esta arquitectura, bautizada como <em>transformer</em>, en muchos otros campos se descubre altamente eficaz hasta el punto de relegar a las arquitecturas recurrentes a un segundo plano. El transformer sería, además, uno de los elementos fundamentales de los modelos preentrenados que estudiaremos más adelante y que comenzarían a aparecer en los meses o años siguientes.</p>
<div class="section" id="el-transformer">
<h2>El transformer<a class="headerlink" href="#el-transformer" title="Permalink to this headline">¶</a></h2>
<p>Como primera aproximación, puedes usar la guía ilustrada de Jay Alammar sobre el <a class="reference external" href="http://jalammar.github.io/illustrated-transformer/">transformer</a>.</p>
<p>Los contenidos nucleares del tema son los incluidos en las secciones 11.1 (“Bidirectional transformer encoders”) y 9.7 (“Self-attention networks: transformers”) de la tercera edición del libro “<a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/">Speech and language processing</a>”. Además, la arquitectura completa codificador-descodificador del transformer se presenta en el apartado 10.6. La aplicación del transformer a algunas tareas de procesamiento del lenguaje natural se ve en 9.8 y 9.9. Los modelos preentrenados se estudian en los apartados 11.2 y 11.3. La estrategia de búsqueda <em>beam search</em> y la tokenización en subpalabras se exploran en 10.5 y 2.4.3, respectivamente. Los elementos más básicos, comunes a cualquier tipo de arquitectura neuronal, se estudian en el capítulo 7. Aunque las hemos estudiado más por encima, el capítulo 9 se centra en las arquitecturas recurrentes. Usa todos esos contenidos junto con los apuntes de clase en tu aprendizaje.</p>
<div class="note admonition">
<p class="admonition-title">Nota</p>
<p>Las representaciones aprendidas tras el entrenamiento por un transformer en cada una de sus capas para una nueva frase de entrada pueden considerarse (de la misma manera que con una red recurrente) como embeddings contextuales de los diferentes tokens de la entrada que pueden usarse a la hora de representarlos en otras tareas. En principio, cualquier capa puede ser adecuada para obtener estas representaciones, pero algunos trabajos han demostrado que ciertas capas son más adecuadas que otras para ciertas tareas. Las capas más cercanas a la entrada parecen representar información más relacionada con la morfología, mientras que las capas finales se relacionan más con la semántica.</p>
</div>
<div class="section" id="ecuaciones-del-transformer">
<h3>Ecuaciones del transformer<a class="headerlink" href="#ecuaciones-del-transformer" title="Permalink to this headline">¶</a></h3>
<p>El transformer usa la arquitectura codificador-descodificador para emitir de forma autoregresiva una secuencia de salida <span class="math notranslate nohighlight">\(\boldsymbol{y}= y_1, y_2,\ldots,y_n\)</span> a partir de una secuencia de entrada <span class="math notranslate nohighlight">\(\boldsymbol{x}= x_1, x_2,\ldots,x_n\)</span>. Habitualmente cada <span class="math notranslate nohighlight">\(x_i\)</span> será un embedding <em>no contextual</em> para el token correspondiente de la frase a procesar obtenido de una tabla de embeddings, y cada <span class="math notranslate nohighlight">\(y_i\)</span> será el vector de probabilidades correspondiente al <span class="math notranslate nohighlight">\(i\)</span>-ésimo token de la frase de salida.</p>
<p>El codificador tiene <span class="math notranslate nohighlight">\(N\)</span> capas idénticas, cada una formada a su vez por dos subcapas:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\underline{\boldsymbol{h}}^l &amp;=&amp; \text{LN}\left(\text{SelfAtt}\left(\boldsymbol{h}^{l-1}\right) + \boldsymbol{h}^{l-1}\right) \\[2ex]
\boldsymbol{h}^l &amp;=&amp; \text{LN}\left(\text{FF}\left(\underline{\boldsymbol{h}}^l\right) + \underline{\boldsymbol{h}}^l\right)
\end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\boldsymbol{h}^l = \{h_1^l,h_2^l,\ldots,h_n^l\}\)</span> son las salidas de la capa <span class="math notranslate nohighlight">\(l\)</span>-ésima (una por cada token de la entrada). La salida de la primera capa es <span class="math notranslate nohighlight">\(\boldsymbol{h}^0= \boldsymbol{x}\)</span>. La función LN obtiene la normalización a nivel de capa, SelfAtt es el mecanismo de atención con múltiples cabezales y FF es una red hacia delante completamente conectada.</p>
<p>El descodificador sigue un planteamiento similar con un par de particularidades: el mecanismo de autoatención usa una máscara para no usar los embeddings de los tokens aún no generados y aparece una tercera subcapa responsable de la atención hacia el codificador:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\underline{\boldsymbol{s}}^l &amp;=&amp; \text{LN}\left(\text{MaskedSelfAtt}\left(\boldsymbol{s}^{l-1}\right) + \boldsymbol{s}^{l-1}\right) \\[2ex]
\underline{\underline{\boldsymbol{s}}}^l &amp;=&amp; \text{LN}\left(\text{CrossAtt}\left(\underline{\boldsymbol{s}}^{l},\boldsymbol{h}^N\right) + \underline{\boldsymbol{s}}^{l}\right) \\[2ex]
\boldsymbol{s}^l &amp;=&amp; \text{LN}\left(\text{FF}\left(\underline{\underline{\boldsymbol{s}}}^l\right) + \underline{\underline{\boldsymbol{s}}}^l\right)
\end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\boldsymbol{s}^l\)</span> son las salidas de la capa <span class="math notranslate nohighlight">\(l\)</span>-ésima del descodificador. Los embeddings de la última capa <span class="math notranslate nohighlight">\(\boldsymbol{s}^M\)</span> se pasan por una capa densa adicional seguida de una función softmax para obtener la estimación de la probabilidad del token correspondiente. La salida de la primera capa del descodificador <span class="math notranslate nohighlight">\(\boldsymbol{s}^0\)</span> es, como en el codificador, un embedding no contextual del token anterior (por ejemplo, el token de mayor probabilidad emitido en el paso anterior).</p>
<div class="figure align-default" id="fig-selfatt">
<a class="reference internal image-reference" href="_images/self-attention_multihead-romain-futrzynski.svg"><img alt="_images/self-attention_multihead-romain-futrzynski.svg" height="700px" src="_images/self-attention_multihead-romain-futrzynski.svg" /></a>
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text">Una representación tridimensional del mecanismo de autoatención tomada del <a class="reference external" href="https://peltarion.com/blog/data-science/self-attention-video">tutorial</a> de Romain Futrzynski.</span><a class="headerlink" href="#fig-selfatt" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="un-simil-del-mecanismo-de-autoatencion">
<h3>Un símil del mecanismo de autoatención<a class="headerlink" href="#un-simil-del-mecanismo-de-autoatencion" title="Permalink to this headline">¶</a></h3>
<p>El mecanismo de autoatención se puede introducir con propósitos didácticos basándonos en una hipotética versión de Python en la que se permitiera acceder a los valores de un diccionario usando claves <em>aproximadas</em>. Supongamos el siguiente diccionario de Python almacenado en la variable <code class="docutils literal notranslate"><span class="pre">d</span></code>; como cualquier diccionario de Python este contiene también un conjunto de claves (<code class="docutils literal notranslate"><span class="pre">manzana</span></code>, por ejemplo) y sus valores asociados (<code class="docutils literal notranslate"><span class="pre">8</span></code> es el valor asociado a la clave <code class="docutils literal notranslate"><span class="pre">manzana</span></code>, por ejemplo):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;manzana&quot;</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="s2">&quot;albaricoque&quot;</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;naranja&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">}</span>
</pre></div>
</div>
<p>En Python <em>convencional</em> ahora podemos realizar una <em>consulta</em> al diccionario con una sintaxis como <code class="docutils literal notranslate"><span class="pre">d[&quot;manzana&quot;]</span></code> para obtener el valor <code class="docutils literal notranslate"><span class="pre">8</span></code>. El intérprete de Python ha usado el nombre de nuestra consulta (<code class="docutils literal notranslate"><span class="pre">manzana</span></code>) para buscar entre todas las claves del diccionario una cuyo nombre coincida <em>exactamente</em> y devolver su valor (<code class="docutils literal notranslate"><span class="pre">8</span></code> en este caso).</p>
<p>Observa cómo en la discusión anterior hemos usado los términos “consulta” (<em>query</em>), “clave” (<em>key</em>) y “valor” (<em>value</em>) que aparecen tambien cuando se discute el mencanismo de autoatención del transformer.</p>
<p>Vayamos ahora más allá y consideremos que realizamos una consulta como <code class="docutils literal notranslate"><span class="pre">d[&quot;narancoque&quot;]</span></code>. Un intérprete de Python <em>real</em> lanzará una excepción ante la consulta anterior, pero un intérprete <em>imaginario</em> podría recorrer el diccionario, comparar el término de la consulta con cada clave del diccionario y ponderar los valores en función del parecido encontrado. Consideremos una función <code class="docutils literal notranslate"><span class="pre">similitud</span></code> que recibe dos cadenas y devuelve un número, no necesariamente acotado, que es mayor cuanto más parecidas son las cadenas (los valores concretos no son ahora relevantes):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>similitud(&quot;narancoque&quot;,&quot;manzana&quot;) → 0
similitud(&quot;narancoque&quot;,&quot;albaricoque&quot;) → 20
similitud(&quot;narancoque&quot;,&quot;naranja&quot;) → 30
</pre></div>
</div>
<p>Estos resultados normalizados para que su suma sea 1 son <code class="docutils literal notranslate"><span class="pre">0</span></code>, <code class="docutils literal notranslate"><span class="pre">0,4</span></code> y <code class="docutils literal notranslate"><span class="pre">0,6</span></code>. Nuestro intérprete de Python imaginario podría ahora devolvernos para la consulta <code class="docutils literal notranslate"><span class="pre">d[&quot;narancoque&quot;]</span></code> el valor 0 x 8 + 0,4 x 4 + 0,6 x 3 = 3,4.</p>
<p>En el caso del transformer, las consultas, las claves y los valores son vectores de una cierta dimensión, y la función de similitud empleada es el producto escalar de la consulta y las diferentes claves. Los grados de similitud se normalizan mediante la función softmax y se utlizan igualmente para ponderar después los distintos valores:</p>
<div class="math notranslate nohighlight">
\[
\text{SelfAtt}(Q,K,V) = \text{softmax}\left( \frac{Q K^T}{\sqrt{d_k}} \right) V
\]</div>
</div>
<div class="section" id="normalizacion-de-capa">
<h3>Normalización de capa<a class="headerlink" href="#normalizacion-de-capa" title="Permalink to this headline">¶</a></h3>
<p>Sean <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> y <span class="math notranslate nohighlight">\(\hat{\sigma}^2\)</span> la media y la varianza, respectivamente, de todas las entradas, que representaremos por <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>, a las neuronas de una capa formada por H neuronas:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\hat{\mu} &amp;=&amp; \frac{1}{H} \sum_{i=1}^H x_i \\[1.5ex]
\hat{\sigma}^2 &amp;=&amp; \frac{1}{H} \sum_{i=1}^H \left(x_i - \hat{\mu} \right)^2 + \epsilon
\end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\epsilon\)</span> tiene un valor muy pequeño para evitar que la una división por cero en la siguiente ecuación. La función LN de normalización para cada entrada de la capa se define como la estandarización:</p>
<div class="math notranslate nohighlight">
\[
\text{LN}(x_i) = \gamma_i \frac{x_i - \hat{\mu}}{\hat{\sigma}^2} + \beta
\]</div>
<p>La fracción permite que todos las entradas de la capa en un determinado instante tengan media cero y varianza 1. Como estos valores son arbitrarios, en cualquier caso, se añaden dos parámetros aprendibles <span class="math notranslate nohighlight">\(\boldsymbol{\gamma}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> para reescalarlos. Los valores normalizados se convierten en la nueva entrada de cada neurona y a estos se aplica la función de activación que corresponda; en el caso del transformer, no hay ninguna función de activación adicional.</p>
</div>
</div>
<div class="section" id="visualizacion-de-embeddings-contextuales">
<h2>Visualización de embeddings contextuales<a class="headerlink" href="#visualizacion-de-embeddings-contextuales" title="Permalink to this headline">¶</a></h2>
<p>Mediante la herramienta <a class="reference external" href="https://huggingface.co/exbert/?model=bart-large&amp;modelKind=bidirectional&amp;sentence=The%20moon%20is%20shinning%20brightly%20tonight.">exBERT</a> vamos a explorar visualmente las representaciones intermedias obtenidas en el codificador de un transformer.</p>
<p>En la <a class="reference external" href="https://www.youtube.com/watch?v=e31oyfo_thY">herramienta</a> puedes seleccionar el modelo a utilizar (en estos momentos no hemos estudiado las diferencias entre ellas, por lo que con <em>BART</em> es suficiente), la frase de entrada, el grado de la atención, las capas y los cabezales a mostrar. La capa superior (la más alejada de la entrada) está a la izquierda. Para seleccionar o deseleccionar un cabezal puedes hacer clic en las columnas. Puedes seleccionar un token haciendo clic sobre él y ocultarlo con doble clic. Al colocarte sobre una palabra puedes ver la predicción que haría el modelo del token que corresponde al embedding obtenido por la red en esa posición, capa y cabezal; observa que si ocultas <em>moon</em> a la derecha, por ejemplo, a la izquierda el sistema tiende a predecir <em>sun</em> en esa posición.</p>
</div>
<div class="section" id="para-saber-mas">
<h2>Para saber más<a class="headerlink" href="#para-saber-mas" title="Permalink to this headline">¶</a></h2>
<p>“<a class="reference external" href="https://nlp.seas.harvard.edu/2018/04/03/attention.html">The annotated transformer</a>” es un documento que va mostrando paso a paso el artículo científico original del transformer y su <em>traslación</em> a código en Python. Este material es opcional y de una complejidad superior a la requerida en la asignatura, pero es la mejor manera de entender la arquitectura a bajo nivel.</p>
</div>
<div class="section" id="referencias">
<h2>Referencias<a class="headerlink" href="#referencias" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-bloque2_transformer-0"><dl class="citation">
<dt class="bibtex label" id="allyouneed"><span class="brackets"><a class="fn-backref" href="#id1">VSP+17</a></span></dt>
<dd><p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, <em>Advances in Neural Information Processing Systems</em>, volume 30, 5998–6008. Curran Associates, Inc., 2017. URL: <a class="reference external" href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>.</p>
</dd>
</dl>
</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="bloque2_embeddings.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Representaciones de palabras y oraciones</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="bloque2_practica.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Práctica. Lectura y documentación del código de un extractor de entidades</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Universitat d'Alacant<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>